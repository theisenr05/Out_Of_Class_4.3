{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19344bae",
   "metadata": {},
   "source": [
    "# Column exploration using `polars` tables.\n",
    "\n",
    "In this lecture, we will explore how to use `polars` tables to explore the columns across many files. This will help us find and fix problems with the naming and order of columns across the files.\n",
    "\n",
    "**Basic procedure:** We want to make a column summary table that shows which columns are present in each file. We will do this by:\n",
    "1. Use `glob` to find all files matching a pattern.\n",
    "1. Read in each file as a list of `polars` tables.\n",
    "2. Stack all columns and aggregate to find unique columns and their counts.\n",
    "3. Create an columns containing the literal value of `1`.\n",
    "4. Use a reduction to join all the tables together on the column names.\n",
    "5. Replace missing values with `0`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8386dafd",
   "metadata": {},
   "source": [
    "> <font color=\"orange\"> Your thoughts here </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d94c988",
   "metadata": {},
   "source": [
    "## Aside -- Python `set`s\n",
    "\n",
    "The `set` is a core Python data structure that represents a unique collection of labels and provides set operations like `union`, `intersection`, etc.  Sets can be constructed using either the `set` type constructor or using `{}` as delimiters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9790cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a', 'b', 'd'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = ['a', 'a', 'b', 'd']\n",
    "s1 = set(L)\n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89e817c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a', 'c', 'd'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2 = {'a', 'c', 'd'}\n",
    "s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc868e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_set = set()\n",
    "empty_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62e432f",
   "metadata": {},
   "source": [
    "#### Set operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecf08b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a', 'b', 'c', 'd'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.union(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a39b6660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a', 'b', 'c', 'd'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 | s2 # Union operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1356a1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import or_\n",
    "\n",
    "or_(s1, s2)  # This function is useful when reducing a sequence of sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7bcb16bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a', 'd'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.intersection(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "089551a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a', 'd'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 & s2  # Intersections operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "949bc6cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a', 'd'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import and_\n",
    "\n",
    "and_(s1, s2)  # This function is useful when reducing a sequence of sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9498519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'b', 'c'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.symmetric_difference(s2) # In one but not both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dca87e26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'b', 'c'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import xor\n",
    "\n",
    "xor(s1, s2)  # This function is useful when reducing a sequence of sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2ecc027c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'b'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 - s2 # in s1 but not s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "678ea8fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'c'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2 - s1 # in s2 but not s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2242801c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'b'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import sub\n",
    "\n",
    "sub(s1, s2)  # This function is useful when reducing a sequence of sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0966f551",
   "metadata": {},
   "source": [
    "## Task 0 - Part 2 - Explain why we should exclude 2003.\n",
    "\n",
    "**Task.** Inspect the column indicator tables from the last lab and explain why\n",
    "1. The year 2003 is problematic, and\n",
    "2. Why it might make sense to restrict the years to 2004-2015."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a320d1e",
   "metadata": {},
   "source": [
    "<font color=\"orange\"> Your answers here </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3529bfd6",
   "metadata": {},
   "source": [
    "## Task 1A - Finding all Common Columns using aggregation\n",
    "\n",
    "Next you will use both `polars` and `pyspark` (separately) to find the set of column columns using the indicator tables constructed in the previous lab.  To do this, you should\n",
    "\n",
    "1. Read in the parcel column indicator table from the previous lab.\n",
    "2. Drop the 2002 and 2003 indicator columns.\n",
    "3. Compute the column-wise sum across the indicator columns.  Use `sum_horizontal` and a column selector in `polars` and construct a column expression using a list comprehension and `functools.reduce` in `pyspark`.\n",
    "4. Use a window function to compute the maximum number of times a column appears in the tables from 2004-2015.  Does this correspond to the number of files/years?  Explain.\n",
    "5. Use a filter to get the columns common to all the tables from 2004-2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f29ecac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your polars code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8492ea3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your pyspark code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654a98be",
   "metadata": {},
   "source": [
    "## Task 1B - Finding all Common Columns using sets\n",
    "\n",
    "Next we will redo the last task, this time using a more Pythonic approach,\n",
    "\n",
    "1. Create a list of `pyspark/polars` lazy data frames, one for each parcel file from 2004-2015.\n",
    "2. Extract the header from each data frame.\n",
    "3. Apply the `set` constructor onto each list of headers to convert them to Python sets.\n",
    "4. Reduce the list of sets of column labels to the intersection and union of column labels.\n",
    "5. Now use set differences to compare the results from `polars` and `pyspark`, both overall and on a set-by-set basis.\n",
    "\n",
    "Do this with list comprehensions and using the assignment expression to save the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2299781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your polars code here [Steps 1-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "870b9822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your pyspark code here [Steps 1-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0fba94a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Python code here [Steps 3+]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2e119d",
   "metadata": {},
   "source": [
    "## Task 1C - What is going on with the different number of columns?\n",
    "\n",
    "Did you notice that `pyspark` and `polars` gave a different number of columns in the previous lab?  Your work on the previous parts of this task, should offer some ideas about where things go wrong, but it's attack this task programmically.\n",
    "\n",
    "1. Read in your two indicator tables from the previous lab and make sure both are `polars` data frames.\n",
    "2. Add a `source` column to both tables indicating which platform (`polars` or `pyspark`) generated the table.\n",
    "3. Our goal is to find columns in one table that *are not* in the other.  Note that `polars` has a very nice join type (`anti`) for just this purpose.  Perform this join on the two tables to find the mismatched column names and the associated years.\n",
    "4. Use `head` or a `text editor` to inspect the respective years to determine what went wrong.\n",
    "5. Sometimes the easiest solution to this sort of problem is to (BARF) use Excel to open, edit, and re-save a file.  Do this for each of the offending years.  Be sure to maintain the same file names and use `|` as the separator when re-saving the files.\n",
    "6. Rerun your code from the previous lab, as well as the code above, to check that your edits fixed the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "61216440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28414951",
   "metadata": {},
   "source": [
    "<font color=\"orange\">Your findings here.<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c4be91",
   "metadata": {},
   "source": [
    "## Task 2 - One Big Happy File\n",
    "\n",
    "Since we will want to reuse the information generated in this lab, it will be useful to be able save it to a python file.\n",
    "\n",
    "1. Create a python file named `parcel.py` which is saved in the root folder (e.g., the same folder as all notebooks).\n",
    "2. Save set representing the common columns to a variable named `common_columns_2004_to_2015`.\n",
    "3. Save sorted list of common columns to a variable named `sorted_common_columns_2004_to_2015`.\n",
    "4. Restart the kernel and verify that you can import both of these data structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21d70ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9088d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restart and verify this runs.\n",
    "from parcel import common_columns_2004_to_2015, sorted_common_columns_2004_to_2015"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
